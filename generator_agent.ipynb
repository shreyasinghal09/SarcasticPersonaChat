{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gs7-0r3qnDcy"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_aws\n",
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z0B2SFpKxEzG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riyasinghal/miniconda3/envs/cmuf24/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JurYGnPTxNpH",
    "outputId": "3fede089-7258-4887-86cb-6883ced1003c"
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/google/Synthetic-Persona-Chat\n",
    "splits = {'train': 'data/Synthetic-Persona-Chat_train.csv', 'validation': 'data/Synthetic-Persona-Chat_valid.csv', 'test': 'data/Synthetic-Persona-Chat_test.csv'}\n",
    "df_test_persona = pd.read_csv(\"hf://datasets/google/Synthetic-Persona-Chat/\" + splits[\"test\"]) #968 rows\n",
    "\n",
    "# https://huggingface.co/datasets/nikesh66/Sarcasm-dataset\n",
    "df_sarcasm = pd.read_csv(\"hf://datasets/nikesh66/Sarcasm-dataset/sarcasm_tweets.csv\")\n",
    "sarcastic_rows = df_sarcasm[df_sarcasm[\"Sarcasm (yes/no)\"] == \"yes\"] #2500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hmb_p1nyxq5C"
   },
   "outputs": [],
   "source": [
    "def sample_persona_pair(df):\n",
    "    sampled_row = df.sample(n=1).iloc[0]\n",
    "    return {\n",
    "        \"user1_persona\": sampled_row[\"user 1 personas\"],\n",
    "        \"user2_persona\": sampled_row[\"user 2 personas\"],\n",
    "        \"conversation\": sampled_row[\"Best Generated Conversation\"]\n",
    "    }\n",
    "\n",
    "def sample_sarcastic_examples(df):\n",
    "  # sarcastic_samples = df[\"Tweet\"].sample(n=5, random_state=42).to_list()\n",
    "  sarcastic_samples = df[\"Tweet\"].sample(n=5).to_list()\n",
    "\n",
    "  return sarcastic_samples\n",
    "\n",
    "random_sample = sample_persona_pair(df_test_persona)\n",
    "sarcastic_samples = sample_sarcastic_examples(df_sarcasm)\n",
    "\n",
    "# print(\"User 1 Persona:\", random_sample[\"user1_persona\"])\n",
    "# print(\"User 2 Persona:\", random_sample[\"user2_persona\"])\n",
    "# print(\"Conversation:\", random_sample[\"conversation\"])\n",
    "# print(\"\\n\\n\")\n",
    "# print(sarcastic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ms82qnsbmqB1"
   },
   "outputs": [],
   "source": [
    "llm = ChatBedrock(\n",
    "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
    "    # model_id = \"meta.llama3-1-8b-instruct-v1:0\",\n",
    "    model_kwargs=dict(temperature=0.9),\n",
    "    aws_access_key_id=\"AKIAQXUIX3RJR2NPZQ47\",\n",
    "    aws_secret_access_key=\"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\",\n",
    "    region_name=\"us-east-1\",\n",
    "    max_tokens = 1500\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\" Your task is to generate conversations that incorporate some sarcasm in the tone. The conversations must feel natural and reflect the given user profiles, with implicit indications of their traits, interests, or personalities. Follow these guidelines to ensure quality: The conversation must be more than 5 turns and less than 8 turns. The\n",
    "#               conversation must be natural, and not direct copies of their profiles. Sarcasm should appear naturally within the conversation, and not all turns need to include sarcasm.\n",
    "#               Sarcasm can range from playful and lighthearted to sharper, as long as it aligns with the users' personalities. The conversation must be more than 5 turns and less than 8 turns. The conversation must be natural, and not direct copies of their profiles.\"\"\",\n",
    "#                       ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"\"\"\n",
    "#             Here, we list the profiles of two users, user 1 and user 2, followed by an interesting and natural conversation between user 1 and user 2, which implicitly reflects their user profiles. We also list some sarcastic statements.\n",
    "#               User 1 Profile: {user_1_profile}\n",
    "#               User 2 Profile: {user_2_profile}\n",
    "#               Conversation: {original_conversation}\n",
    "#               Sarcastic Statements: {sarcastic_statements}\n",
    "#               \"\"\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to generate conversations that incorporate sarcasm naturally and creatively. Each conversation must reflect the personalities, interests, and traits of the given user profiles, using sarcasm in ways that are contextually appropriate and tailored to the users' traits. Follow these guidelines:\n",
    "\n",
    "              1. Natural Flow: The conversation should feel organic and realistic, reflecting the users' personalities implicitly.\n",
    "              2. Sarcasm: Use sarcasm ranging from playful to sharp, as long as it aligns with the tone of the conversation and the users' traits. Not every turn needs to be sarcastic.\n",
    "              3. Creative Adaptation: Use the sarcastic examples provided only for tone inspiration. Do not use the same phrases or replicate their structure directly. Instead, derive unique, contextually fitting sarcasm that feels natural to the conversation.\n",
    "              4. Length: Keep the conversation between 4 and 7 turns.\n",
    "              5. Originality: All elements of the conversation, including sarcastic remarks, should be distinct and avoid direct borrowing from the examples.\n",
    "\n",
    "              Keep in mind: The examples are there to help you understand the tone and style, not to be copied verbatim. Use them as a creative springboard to generate unique and personalized interactions.\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            Here, we list the profiles of two users, User 1 and User 2, followed by an interesting and natural conversation between them, which implicitly reflects their user profiles. Sarcasm should be used in a manner inspired by the examples without repeating them.\n",
    "\n",
    "              User 1 Profile: {user_1_profile}\n",
    "              User 2 Profile: {user_2_profile}\n",
    "              Conversation: {original_conversation}\n",
    "              Sarcastic Examples (for tone inspiration only): {sarcastic_statements}\n",
    "              \"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7AMWEwf-2l9m"
   },
   "outputs": [],
   "source": [
    "# response = chain.invoke(\n",
    "#     {\n",
    "#         \"user_1_profile\": random_sample[\"user1_persona\"],\n",
    "#         \"user_2_profile\": random_sample[\"user2_persona\"],\n",
    "#         \"original_conversation\": random_sample[\"conversation\"],\n",
    "#         \"sarcastic_statements\": sarcastic_samples\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(random_sample[\"user1_persona\"])\n",
    "# print(\"\\n\\n\")\n",
    "# print(random_sample[\"user2_persona\"])\n",
    "# print(\"\\n\\n\")\n",
    "\n",
    "# print(len(random_sample[\"conversation\"].split(\" \")))\n",
    "# # print(\"\\n\\n\")\n",
    "# # print(sarcastic_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPq3jyGCKkKB",
    "outputId": "49198e3f-4752-4f02-9592-28241eaa9722"
   },
   "outputs": [],
   "source": [
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdbsAjd8Hqqs"
   },
   "source": [
    "Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEaXOWZhHLmK",
    "outputId": "d079f5e5-aaec-4829-e0d0-1e6550aee6d3"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "    random_sample = sample_persona_pair(df_test_persona)\n",
    "    sarcastic_samples = sample_sarcastic_examples(df_sarcasm)\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"user_1_profile\": random_sample[\"user1_persona\"],\n",
    "            \"user_2_profile\": random_sample[\"user2_persona\"],\n",
    "            \"original_conversation\": random_sample[\"conversation\"],\n",
    "            \"sarcastic_statements\": sarcastic_samples\n",
    "        }\n",
    "    )\n",
    "    generated_conversation = response.content\n",
    "\n",
    "    data.append({\n",
    "        \"User_1_Profile\": random_sample[\"user1_persona\"],\n",
    "        \"User_2_Profile\": random_sample[\"user2_persona\"],\n",
    "        \"Original_Conversation\": random_sample[\"conversation\"],\n",
    "        \"Sarcastic_Samples\": sarcastic_samples,\n",
    "        \"Generated_Conversation\": generated_conversation\n",
    "    })\n",
    "\n",
    "df_output = pd.DataFrame(data)\n",
    "df_output.to_csv(\"generated_datasets/experiment1/mistral_generator.csv\", index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"CSV file has been saved successfully! Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvZVxLFDHfri"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cmuf24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
