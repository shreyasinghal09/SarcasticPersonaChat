{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gs7-0r3qnDcy"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_aws\n",
        "# !pip install transformers\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z0B2SFpKxEzG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import random\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from langchain_aws import ChatBedrock\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JurYGnPTxNpH",
        "outputId": "3fede089-7258-4887-86cb-6883ced1003c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# https://huggingface.co/datasets/google/Synthetic-Persona-Chat\n",
        "splits = {'train': 'data/Synthetic-Persona-Chat_train.csv', 'validation': 'data/Synthetic-Persona-Chat_valid.csv', 'test': 'data/Synthetic-Persona-Chat_test.csv'}\n",
        "df_test_persona = pd.read_csv(\"hf://datasets/google/Synthetic-Persona-Chat/\" + splits[\"test\"]) #968 rows\n",
        "\n",
        "# https://huggingface.co/datasets/nikesh66/Sarcasm-dataset\n",
        "df_sarcasm = pd.read_csv(\"hf://datasets/nikesh66/Sarcasm-dataset/sarcasm_tweets.csv\")\n",
        "sarcastic_rows = df_sarcasm[df_sarcasm[\"Sarcasm (yes/no)\"] == \"yes\"] #2500 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hmb_p1nyxq5C"
      },
      "outputs": [],
      "source": [
        "def sample_persona_pair(df):\n",
        "    sampled_row = df.sample(n=1).iloc[0]\n",
        "    return {\n",
        "        \"user1_persona\": sampled_row[\"user 1 personas\"],\n",
        "        \"user2_persona\": sampled_row[\"user 2 personas\"],\n",
        "        \"conversation\": sampled_row[\"Best Generated Conversation\"]\n",
        "    }\n",
        "\n",
        "def sample_sarcastic_examples(df):\n",
        "  # sarcastic_samples = df[\"Tweet\"].sample(n=5, random_state=42).to_list()\n",
        "  sarcastic_samples = df[\"Tweet\"].sample(n=5).to_list()\n",
        "\n",
        "  return sarcastic_samples\n",
        "\n",
        "random_sample = sample_persona_pair(df_test_persona)\n",
        "sarcastic_samples = sample_sarcastic_examples(df_sarcasm)\n",
        "\n",
        "# print(\"User 1 Persona:\", random_sample[\"user1_persona\"])\n",
        "# print(\"User 2 Persona:\", random_sample[\"user2_persona\"])\n",
        "# print(\"Conversation:\", random_sample[\"conversation\"])\n",
        "# print(\"\\n\\n\")\n",
        "# print(sarcastic_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ms82qnsbmqB1"
      },
      "outputs": [],
      "source": [
        "llm = ChatBedrock(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    model_kwargs=dict(temperature=0.9),\n",
        "    aws_access_key_id=\"AKIAQXUIX3RJR2NPZQ47\",\n",
        "    aws_secret_access_key=\"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\",\n",
        "    region_name=\"us-east-1\",\n",
        "    max_tokens = 1000\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\n",
        "#             \"system\",\n",
        "#             \"\"\" Your task is to generate conversations that incorporate some sarcasm in the tone. The conversations must feel natural and reflect the given user profiles, with implicit indications of their traits, interests, or personalities. Follow these guidelines to ensure quality: The conversation must be more than 5 turns and less than 8 turns. The\n",
        "#               conversation must be natural, and not direct copies of their profiles. Sarcasm should appear naturally within the conversation, and not all turns need to include sarcasm.\n",
        "#               Sarcasm can range from playful and lighthearted to sharper, as long as it aligns with the users' personalities. The conversation must be more than 5 turns and less than 8 turns. The conversation must be natural, and not direct copies of their profiles.\"\"\",\n",
        "#                       ),\n",
        "#         (\n",
        "#             \"human\",\n",
        "#             \"\"\"\n",
        "#             Here, we list the profiles of two users, user 1 and user 2, followed by an interesting and natural conversation between user 1 and user 2, which implicitly reflects their user profiles. We also list some sarcastic statements.\n",
        "#               User 1 Profile: {user_1_profile}\n",
        "#               User 2 Profile: {user_2_profile}\n",
        "#               Conversation: {original_conversation}\n",
        "#               Sarcastic Statements: {sarcastic_statements}\n",
        "#               \"\"\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"Your task is to generate conversations that incorporate sarcasm naturally and creatively. Each conversation must reflect the personalities, interests, and traits of the given user profiles, using sarcasm in ways that are contextually appropriate and tailored to the users' traits. Follow these guidelines:\n",
        "\n",
        "              1. Natural Flow: The conversation should feel organic and realistic, reflecting the users' personalities implicitly.\n",
        "              2. Sarcasm: Use sarcasm ranging from playful to sharp, as long as it aligns with the tone of the conversation and the users' traits. Not every turn needs to be sarcastic.\n",
        "              3. Creative Adaptation: Use the sarcastic examples provided only for tone inspiration. Do not use the same phrases or replicate their structure directly. Instead, derive unique, contextually fitting sarcasm that feels natural to the conversation.\n",
        "              4. Length: Keep the conversation between 4 and 7 turns.\n",
        "              5. Originality: All elements of the conversation, including sarcastic remarks, should be distinct and avoid direct borrowing from the examples.\n",
        "\n",
        "              Keep in mind: The examples are there to help you understand the tone and style, not to be copied verbatim. Use them as a creative springboard to generate unique and personalized interactions.\"\"\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"\"\"\n",
        "            Here, we list the profiles of two users, User 1 and User 2, followed by an interesting and natural conversation between them, which implicitly reflects their user profiles. Sarcasm should be used in a manner inspired by the examples without repeating them.\n",
        "\n",
        "              User 1 Profile: {user_1_profile}\n",
        "              User 2 Profile: {user_2_profile}\n",
        "              Conversation: {original_conversation}\n",
        "              Sarcastic Examples (for tone inspiration only): {sarcastic_statements}\n",
        "              \"\"\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"user_1_profile\": random_sample[\"user1_persona\"],\n",
        "        \"user_2_profile\": random_sample[\"user2_persona\"],\n",
        "        \"original_conversation\": random_sample[\"conversation\"],\n",
        "        \"sarcastic_statements\": sarcastic_samples\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "7AMWEwf-2l9m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_sample[\"user1_persona\"])\n",
        "print(\"\\n\\n\")\n",
        "print(random_sample[\"user2_persona\"])\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(len(random_sample[\"conversation\"].split(\" \")))\n",
        "# print(\"\\n\\n\")\n",
        "# print(sarcastic_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdyHOVSwKymG",
        "outputId": "4d94a133-0967-488a-9f45-ce338cc59774"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I lift weights every weekend.\n",
            "I am big and tall.\n",
            "I like making barbecue.\n",
            "I work in a warehouse driving a forklift.\n",
            "\n",
            "\n",
            "\n",
            "I am currently attending school.\n",
            "I like music.\n",
            "I have one sibling and two parents.\n",
            "My family has four people in it.\n",
            "I am five feet tall.\n",
            "\n",
            "\n",
            "\n",
            "291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPq3jyGCKkKB",
        "outputId": "49198e3f-4752-4f02-9592-28241eaa9722"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " User 1: Hey, I'm [user 1], the strong and mighty forklift driver.\n",
            "\n",
            "User 2: Hi, I'm [user 2], the petite music enthusiast.\n",
            "\n",
            "User 1: What do you do to keep yourself entertained, little one?\n",
            "\n",
            "User 2: I like to listen to music and hang out with friends.\n",
            "\n",
            "User 1: Ah, the classic \"listen to music and hang out with friends.\" I've heard that one before.\n",
            "\n",
            "User 2: It's a classic for a reason, isn't it?\n",
            "\n",
            "User 1: I suppose so. I, on the other hand, lift heavy objects and move them around all day.\n",
            "\n",
            "User 2: That sounds like a real thrill.\n",
            "\n",
            "User 1: It is! I mean, who wouldn't want to spend their days maneuvering massive loads and feeling the power of a forklift in their hands?\n",
            "\n",
            "User 2: I can only imagine.\n",
            "\n",
            "User 1: Trust me, it's a blast.\n",
            "\n",
            "User 2: I'm sure it is. I'll stick to my music and friends, though.\n",
            "\n",
            "User 1: Suit yourself.\n",
            "\n",
            "User 2: I'll be sure to enjoy it while you're off lifting things.\n",
            "\n",
            "User 1: I'll be sure to enjoy my day of heavy lifting while you're off enjoying your music and friends.\n",
            "\n",
            "User 2: Sounds like a plan.\n",
            "\n",
            "User 1: Indeed.\n",
            "\n",
            "User 2: So, what are you up to this weekend?\n",
            "\n",
            "User 1: I'm not sure yet. I might go to the gym, or I might just relax at home.\n",
            "\n",
            "User 2: I'll be going to a concert this weekend.\n",
            "\n",
            "User 1: A concert, huh? How exciting. I'll be here, lifting things and feeling the power of a forklift in my hands.\n",
            "\n",
            "User 2: I'm sure that's a real thrill.\n",
            "\n",
            "User 1: It is! I mean, who wouldn't want to spend their weekends moving massive loads and feeling the power of a forklift in their hands?\n",
            "\n",
            "User 2: I can only imagine.\n",
            "\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation Pipeline"
      ],
      "metadata": {
        "id": "GdbsAjd8Hqqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    random_sample = sample_persona_pair(df_test_persona)\n",
        "    sarcastic_samples = sample_sarcastic_examples(df_sarcasm)\n",
        "\n",
        "    response = chain.invoke(\n",
        "        {\n",
        "            \"user_1_profile\": random_sample[\"user1_persona\"],\n",
        "            \"user_2_profile\": random_sample[\"user2_persona\"],\n",
        "            \"original_conversation\": random_sample[\"conversation\"],\n",
        "            \"sarcastic_statements\": sarcastic_samples\n",
        "        }\n",
        "    )\n",
        "    generated_conversation = response.content\n",
        "\n",
        "    data.append({\n",
        "        \"User_1_Profile\": random_sample[\"user1_persona\"],\n",
        "        \"User_2_Profile\": random_sample[\"user2_persona\"],\n",
        "        \"Original_Conversation\": random_sample[\"conversation\"],\n",
        "        \"Sarcastic_Samples\": sarcastic_samples,\n",
        "        \"Generated_Conversation\": generated_conversation\n",
        "    })\n",
        "\n",
        "df_output = pd.DataFrame(data)\n",
        "df_output.to_csv(\"generated_conversations.csv\", index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"CSV file has been saved successfully! Time taken: {elapsed_time:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEaXOWZhHLmK",
        "outputId": "d079f5e5-aaec-4829-e0d0-1e6550aee6d3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been saved successfully! Time taken: 67.13 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fvZVxLFDHfri"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}